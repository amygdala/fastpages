{
  
    
        "post0": {
            "title": "Getting explanations for AutoML Tables predictions",
            "content": "Introduction . Google Cloud’s AutoML Tables lets you automatically build and deploy state-of-the-art machine learning models using your own structured data. . AutoML Tables now has an easier-to-use Tables-specific Python client library, as well as a new ability to explain online prediction results— called local feature importance— which gives visibility into how the features in a specific prediction request informed the resulting prediction. . In this notebook, we&#39;ll create a custom Tables model to predict duration of London bike rentals given information about local weather as well as info about the rental trip. We&#39;ll walk through examples of using the Tables client libraries for creating a dataset, training a custom model, deploying the model, and using it to make predictions; and show how you can programmatically request local feature importance information. . We recommend running this notebook using AI Platform Notebooks. If you want to run the notebook on colab (or locally), it&#39;s possible, but you&#39;ll need to do a bit more setup. See the Appendix section of this notebook for details. . Before you begin . Follow the AutoML Tables documentation to: . Select or create a GCP project. | Make sure that billing is enabled for your project | Enable the Cloud AutoML and Storage APIs. | (Recommended) Create an AI Platform Notebook instance and upload this notebook to it. | . (See also the Quickstart guide for a getting-started walkthrough on AutoML Tables). . Then, install the AutoML Python client libraries into your notebook environment: . !pip3 install -U google-cloud-automl . You may need to restart your notebook kernel after running the above to pick up the installation. . Enter your GCP project ID in the cell below, then run the cell. . PROJECT_ID = &quot;&lt;your-project-id&gt;&quot; . Do some imports . Next, import some libraries and set some variables. . import argparse import os from google.api_core.client_options import ClientOptions from google.cloud import automl_v1beta1 as automl import google.cloud.automl_v1beta1.proto.data_types_pb2 as data_types . REGION = &#39;us-central1&#39; DATASET_NAME = &#39;bikes-weather&#39; BIGQUERY_PROJECT_ID = &#39;aju-dev-demos&#39; DATASET_ID = &#39;london_bikes_weather&#39; TABLE_ID = &#39;bikes_weather&#39; IMPORT_URI = &#39;bq://%s.%s.%s&#39; % (BIGQUERY_PROJECT_ID, DATASET_ID, TABLE_ID) print(IMPORT_URI) . DATASET_NAME = &#39;bikes_weather&#39; . Create a dataset, and import data . Next, we&#39;ll define some utility functions to create a dataset, and to import data into a dataset. The client.import_data() call returns an operation future that can be used to check for completion synchronously or asynchronously— in this case we wait synchronously. . def create_dataset(client, dataset_display_name): &quot;&quot;&quot;Create a dataset.&quot;&quot;&quot; # Create a dataset with the given display name dataset = client.create_dataset(dataset_display_name) # Display the dataset information. print(&quot;Dataset name: {}&quot;.format(dataset.name)) print(&quot;Dataset id: {}&quot;.format(dataset.name.split(&quot;/&quot;)[-1])) print(&quot;Dataset display name: {}&quot;.format(dataset.display_name)) print(&quot;Dataset metadata:&quot;) print(&quot; t{}&quot;.format(dataset.tables_dataset_metadata)) print(&quot;Dataset example count: {}&quot;.format(dataset.example_count)) print(&quot;Dataset create time:&quot;) print(&quot; tseconds: {}&quot;.format(dataset.create_time.seconds)) print(&quot; tnanos: {}&quot;.format(dataset.create_time.nanos)) return dataset . def import_data(client, dataset_display_name, path): &quot;&quot;&quot;Import structured data.&quot;&quot;&quot; response = None if path.startswith(&#39;bq&#39;): response = client.import_data( dataset_display_name=dataset_display_name, bigquery_input_uri=path ) else: # Get the multiple Google Cloud Storage URIs. input_uris = path.split(&quot;,&quot;) response = client.import_data( dataset_display_name=dataset_display_name, gcs_input_uris=input_uris ) print(&quot;Processing import...&quot;) # synchronous check of operation status. print(&quot;Data imported. {}&quot;.format(response.result())) . Next, we&#39;ll create the client object that we&#39;ll use for all our operations. . client = automl.TablesClient(project=PROJECT_ID, region=REGION) . Create the Tables dataset: . create_dataset(client, DATASET_NAME) . ... and then import data from the BigQuery table into the dataset. The import command will take a while to run. Wait until it has returned before proceeding. You can also check import status in the Cloud Console. . (Note that if you run this notebook multiple times, you will get an error if you try to create multiple datasets with the same name. However, you can train multiple models against the same dataset.) . import_data(client, DATASET_NAME, IMPORT_URI) . Update the dataset schema . Now we&#39;ll define utility functions to update dataset and column information. We need these to set the dataset&#39;s target column (the field we&#39;ll train our model to predict) and to change the types of some of the columns. AutoML Tables is pretty good at inferring reasonable column types based on input, but in our case, there are some columns (like bike station IDs) that we want to treat as Categorical instead of Numeric. . def update_column_spec(client, dataset_display_name, column_spec_display_name, type_code, nullable=None): &quot;&quot;&quot;Update column spec.&quot;&quot;&quot; response = client.update_column_spec( dataset_display_name=dataset_display_name, column_spec_display_name=column_spec_display_name, type_code=type_code, nullable=nullable ) # synchronous check of operation status. print(&quot;Table spec updated. {}&quot;.format(response)) def update_dataset(client, dataset_display_name, target_column_spec_name=None, time_column_spec_name=None, test_train_column_spec_name=None): &quot;&quot;&quot;Update dataset.&quot;&quot;&quot; if target_column_spec_name is not None: response = client.set_target_column( dataset_display_name=dataset_display_name, column_spec_display_name=target_column_spec_name ) print(&quot;Target column updated. {}&quot;.format(response)) if time_column_spec_name is not None: response = client.set_time_column( dataset_display_name=dataset_display_name, column_spec_display_name=time_column_spec_name ) print(&quot;Time column updated. {}&quot;.format(response)) . def list_column_specs(client, dataset_display_name, filter_=None): &quot;&quot;&quot;List all column specs.&quot;&quot;&quot; result = [] # List all the table specs in the dataset by applying filter. response = client.list_column_specs( dataset_display_name=dataset_display_name, filter_=filter_) print(&quot;List of column specs:&quot;) for column_spec in response: # Display the column_spec information. print(&quot;Column spec name: {}&quot;.format(column_spec.name)) print(&quot;Column spec id: {}&quot;.format(column_spec.name.split(&quot;/&quot;)[-1])) print(&quot;Column spec display name: {}&quot;.format(column_spec.display_name)) print(&quot;Column spec data type: {}&quot;.format(column_spec.data_type)) result.append(column_spec) return result . Update the dataset to indicate that the target column is duration. . update_dataset(client, DATASET_NAME, target_column_spec_name=&#39;duration&#39;, # time_column_spec_name=&#39;ts&#39; ) . Now we&#39;ll update some of the column types. You can list their default specs first if you like: . list_column_specs(client, DATASET_NAME) . ... and now we&#39;ll update them to the types we want: . update_column_spec(client, DATASET_NAME, &#39;end_station_id&#39;, &#39;CATEGORY&#39;) update_column_spec(client, DATASET_NAME, &#39;start_station_id&#39;, &#39;CATEGORY&#39;) update_column_spec(client, DATASET_NAME, &#39;loc_cross&#39;, &#39;CATEGORY&#39;) update_column_spec(client, DATASET_NAME, &#39;bike_id&#39;, &#39;CATEGORY&#39;) . You can view the results in the Cloud Console. Note that useful stats are generated for each column. You can also run the list_column_specs() function again to see the new config. . # list_column_specs(client, DATASET_NAME) . Train a custom model on the dataset . Now we&#39;re ready to train a model on the dataset. We&#39;ll need to generate a unique name for the model, which we&#39;ll do by appending a timestamp, in case you want to run this notebook multiple times. The 1000 arg in the create_model() call specifies to budget 1 hour of training time. . In the create_model() utility function below, we may not want to block on the result, since total job time can be multiple hours. If you want the function to block until training is complete, uncomment the last line of the function below. . import time MODEL_NAME = &#39;bwmodel_&#39; + str(int(time.time())) print(&#39;MODEL_NAME: %s&#39; % MODEL_NAME) def create_model(client, dataset_display_name, model_display_name, train_budget_milli_node_hours, include_column_spec_names=None, exclude_column_spec_names=None): &quot;&quot;&quot;Create a model.&quot;&quot;&quot; # Create a model with the model metadata in the region. response = client.create_model( model_display_name, train_budget_milli_node_hours=train_budget_milli_node_hours, dataset_display_name=dataset_display_name, include_column_spec_names=include_column_spec_names, exclude_column_spec_names=exclude_column_spec_names, ) print(&quot;Training model...&quot;) print(&quot;Training operation: {}&quot;.format(response.operation)) print(&quot;Training operation name: {}&quot;.format(response.operation.name)) # uncomment the following to block until training is finished. # print(&quot;Training completed: {}&quot;.format(response.result())) . create_model(client, DATASET_NAME, MODEL_NAME, 1000) . Get the status of your training job . Edit the following call to set OP_NAME to the &quot;training operation name&quot; listed in the output of create_model() above. . OP_NAME = &#39;YOUR TRAINING OPERATION NAME&#39; . def get_operation_status(client, operation_full_id): &quot;&quot;&quot;Get operation status.&quot;&quot;&quot; # Get the latest state of a long-running operation. op = client.auto_ml_client.transport._operations_client.get_operation( operation_full_id ) print(&quot;Operation status: {}&quot;.format(op)) from google.cloud.automl import types msg = types.OperationMetadata() print(msg.ParseFromString(op.metadata.value)) . The training job may take several hours. You can check on its status in the Cloud Console UI. You can also monitor it via the get_operation_status() call below. (Make sure you&#39;ve edited the OP_NAME variable value above). You&#39;ll see: done: true in the output when it&#39;s finished. . (Note: if you should lose your notebook kernel context while the training job is running, you can continue the rest of the notebook later with a new kernel: just make note of the MODEL_NAME. You can find that information in the Cloud Console as well). . res = get_operation_status(client, OP_NAME) . Get information about your trained custom model . Once it has been created, you can get information about a specific model. (While the training job is still running, you&#39;ll just get a not found message.) . from google.cloud.automl_v1beta1 import enums from google.api_core import exceptions def get_model(client, model_display_name): &quot;&quot;&quot;Get model details.&quot;&quot;&quot; try: model = client.get_model(model_display_name=model_display_name) except exceptions.NotFound: print(&quot;Model %s not found.&quot; % model_display_name) return (None, None) # Get complete detail of the model.a model = client.get_model(model_display_name=model_display_name) # Retrieve deployment state. if model.deployment_state == enums.Model.DeploymentState.DEPLOYED: deployment_state = &quot;deployed&quot; else: deployment_state = &quot;undeployed&quot; # get features of top global importance feat_list = [ (column.feature_importance, column.column_display_name) for column in model.tables_model_metadata.tables_model_column_info ] feat_list.sort(reverse=True) if len(feat_list) &lt; 10: feat_to_show = len(feat_list) else: feat_to_show = 10 # Display the model information. print(&quot;Model name: {}&quot;.format(model.name)) print(&quot;Model id: {}&quot;.format(model.name.split(&quot;/&quot;)[-1])) print(&quot;Model display name: {}&quot;.format(model.display_name)) print(&quot;Features of top importance:&quot;) for feat in feat_list[:feat_to_show]: print(feat) print(&quot;Model create time:&quot;) print(&quot; tseconds: {}&quot;.format(model.create_time.seconds)) print(&quot; tnanos: {}&quot;.format(model.create_time.nanos)) print(&quot;Model deployment state: {}&quot;.format(deployment_state)) return (model, feat_list) . Don&#39;t proceed with the rest of the notebook until the model has finished training and the following get_model() call returns model information rather than &#39;not found&#39;. . Once the training job has finished, we can get information about the model, including information about which input features proved to be the most important globally (that is, across the full training dataset). . (model, global_feat_importance) = get_model(client, MODEL_NAME) . We can graph the global feature importance values to get a visualization of which inputs were most important in training the model. (The Cloud Console UI also displays such a graph). . print(global_feat_importance) . import matplotlib.pyplot as plt res = list(zip(*global_feat_importance)) x = list(res[0]) y = list(res[1]) y_pos = list(range(len(y))) plt.barh(y_pos, x, alpha=0.5) plt.yticks(y_pos, y) plt.show() . See your model&#39;s evaluation metrics . We can also get model evaluation information once the model is trained. The available metrics depend upon which optimization objective you used. In this example, we used the default, RMSE. . evals = client.list_model_evaluations(model_display_name=MODEL_NAME) list(evals)[1].regression_evaluation_metrics . Use your trained model to make predictions and see explanations of the results . Deploy your model and get predictions + explanations . Once your training job has finished, you can use your model to make predictions. . With online prediction, you can now request explanations of the results, in the form of local feature importance calculations on the inputs. Local feature importance gives you visibility into how the features in a specific prediction request informed the resulting prediction. . To get online predictions, we first need to deploy the model. . Note: see the documentation for other prediction options including the ability to export your custom model and run it in a container anywhere. . def deploy_model(client, model_display_name): &quot;&quot;&quot;Deploy model.&quot;&quot;&quot; response = client.deploy_model(model_display_name=model_display_name) # synchronous check of operation status. print(&quot;Model deployed. {}&quot;.format(response.result())) . It will take a while to deploy the model. Wait for the deploy_model() call to finish before proceeding with the rest of the notebook cells. You can track status in the Console UI as well. . deploy_model(client, MODEL_NAME) . Once the model is deployed, you can access it via the UI, or the API, to make online prediction requests. These can include a request for local feature importance calculations on the inputs, a newly-launched feature. Local feature importance gives you visibility into how the features in a specific prediction request informed the resulting prediction. . def predict(client, model_display_name, inputs, feature_importance=False): &quot;&quot;&quot;Make a prediction.&quot;&quot;&quot; if feature_importance: response = client.predict( model_display_name=model_display_name, inputs=inputs, feature_importance=True, ) else: response = client.predict( model_display_name=model_display_name, inputs=inputs) print(&quot;Prediction results:&quot;) print(response) return response . inputs = { &quot;bike_id&quot;: &quot;5373&quot;, &quot;day_of_week&quot;: &quot;3&quot;, &quot;end_latitude&quot;: 51.52059681, &quot;end_longitude&quot;: -0.116688468, &quot;end_station_id&quot;: &quot;68&quot;, &quot;euclidean&quot;: 3589.5146210024977, &quot;loc_cross&quot;: &quot;POINT(-0.07 51.52)POINT(-0.12 51.52)&quot;, &quot;max&quot;: 44.6, &quot;min&quot;: 34.0, &quot;prcp&quot;: 0, &quot;ts&quot;: &quot;1480407420&quot;, &quot;start_latitude&quot;: 51.52388, &quot;start_longitude&quot;: -0.065076, &quot;start_station_id&quot;: &quot;445&quot;, &quot;temp&quot;: 38.2, &quot;dewp&quot;: 28.6 } . Try running the prediction request first without, then with, the local feature importance calculations, to see the difference in the information that is returned. (The actual duration— that we&#39;re predicting— is 1200.) . predict(client, MODEL_NAME, inputs, feature_importance=False) . response = predict(client, MODEL_NAME, inputs, feature_importance=True) . We can plot the local feature importance values to get a visualization of which fields were most and least important for this particular prediction. . import matplotlib.pyplot as plt col_info = response.payload[0].tables.tables_model_column_info x = [] y = [] for c in col_info: y.append(c.column_display_name) x.append(c.feature_importance) y_pos = list(range(len(y))) plt.barh(y_pos, x, alpha=0.5) plt.yticks(y_pos, y) plt.show() . You can see a similar graphic in the Cloud Console Tables UI when you submit an ONLINE PREDICTION and tick the &quot;Generate feature importance&quot; checkbox. . The local feature importance calculations are specific to a given input instance. . Summary . In this notebook, we showed how you can use the AutoML Tables client library to create datasets, train models, and get predictions from your trained model— and in particular, how you can get explanations of the results along with the predictions. . Appendix: running this notebook on colab (or locally) . It&#39;s possible to run this example on colab, but it takes a bit more setup. Do the following before you create the Tables client object or call the API. . Create a service account, give it the necessary roles (e.g., AutoML Admin) and download a json credentials file for the service account. Upload the credentials file to the colab file system. . Then, edit the following to point to that file, and run the cell: . %env GOOGLE_APPLICATION_CREDENTIALS /content/your-credentials-file.json . Your Tables API calls should now be properly authenticated. If you lose the colab runtime, you&#39;ll need to re-upload the file and re-set the environment variable. . If you&#39;re running the notebook locally, point the GOOGLE_APPLICATION_CREDENTIALS environment variable to the service account credentials file before starting the notebook, e.g.: . export GOOGLE_APPLICATION_CREDENTIALS=/path/to/your-credentials-file.json .",
            "url": "https://amygdala.github.io/gcp_blog/jupyter/2020/04/17/automl_tables_xai.html",
            "relUrl": "/jupyter/2020/04/17/automl_tables_xai.html",
            "date": " • Apr 17, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://amygdala.github.io/gcp_blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://amygdala.github.io/gcp_blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://amygdala.github.io/gcp_blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://amygdala.github.io/gcp_blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}